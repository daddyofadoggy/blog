<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
    <meta charset="utf-8">
    <meta name="generator" content="quarto-1.8.25">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


    <title>ch08 – My Blogs</title>
    <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      div.columns{display: flex; gap: min(4vw, 1.5em);}
      div.column{flex: auto; overflow-x: auto;}
      div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
      ul.task-list{list-style: none;}
      ul.task-list li input[type="checkbox"] {
        width: 0.8em;
        margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
        vertical-align: middle;
      }
      /* CSS for syntax highlighting */
      html { -webkit-text-size-adjust: 100%; }
      pre > code.sourceCode { white-space: pre; position: relative; }
      pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
      pre > code.sourceCode > span:empty { height: 1.2em; }
      .sourceCode { overflow: visible; }
      code.sourceCode > span { color: inherit; text-decoration: inherit; }
      div.sourceCode { margin: 1em 0; }
      pre.sourceCode { margin: 0; }
      @media screen {
      div.sourceCode { overflow: auto; }
      }
      @media print {
      pre > code.sourceCode { white-space: pre-wrap; }
      pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
      }
      pre.numberSource code
        { counter-reset: source-line 0; }
      pre.numberSource code > span
        { position: relative; left: -4em; counter-increment: source-line; }
      pre.numberSource code > span > a:first-child::before
        { content: counter(source-line);
          position: relative; left: -1em; text-align: right; vertical-align: baseline;
          border: none; display: inline-block;
          -webkit-touch-callout: none; -webkit-user-select: none;
          -khtml-user-select: none; -moz-user-select: none;
          -ms-user-select: none; user-select: none;
          padding: 0 4px; width: 4em;
        }
      pre.numberSource { margin-left: 3em;  padding-left: 4px; }
      div.sourceCode
        {   }
      @media screen {
      pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
      }
    </style>

    <style>
      body.hypothesis-enabled #quarto-embed-header {
        padding-right: 36px;
      }

      #quarto-embed-header {
        height: 3em;
        width: 100%;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-bottom: solid 1px;
      }

      #quarto-embed-header h6 {
        font-size: 1.1em;
        padding-top: 0.6em;
        margin-left: 1em;
        margin-right: 1em;
        font-weight: 400;
      }

      #quarto-embed-header a.quarto-back-link,
      #quarto-embed-header a.quarto-download-embed {
        font-size: 0.8em;
        margin-top: 1em;
        margin-bottom: 1em;
        margin-left: 1em;
        margin-right: 1em;
      }

      .quarto-back-container {
        padding-left: 0.5em;
        display: flex;
      }

      .headroom {
          will-change: transform;
          transition: transform 200ms linear;
      }

      .headroom--pinned {
          transform: translateY(0%);
      }

      .headroom--unpinned {
          transform: translateY(-100%);
      }      
    </style>

    <script>
    window.document.addEventListener("DOMContentLoaded", function () {

      var header = window.document.querySelector("#quarto-embed-header");
      const titleBannerEl = window.document.querySelector("body > #title-block-header");
      if (titleBannerEl) {
        titleBannerEl.style.paddingTop = header.clientHeight + "px";
      }
      const contentEl = window.document.getElementById('quarto-content');
      for (const child of contentEl.children) {
        child.style.paddingTop = header.clientHeight + "px";
        child.style.marginTop = "1em";
      }

      // Use the article root if the `back` call doesn't work. This isn't perfect
      // but should typically work
      window.quartoBackToArticle = () => {
        var currentUrl = window.location.href;
        window.history.back();
        setTimeout(() => {
            // if location was not changed in 100 ms, then there is no history back
            if(currentUrl === window.location.href){              
                // redirect to site root
                window.location.href = '/';
            }
        }, 100);
      }

      const headroom = new window.Headroom(header, {
        tolerance: 5,
        onPin: function () {
        },
        onUnpin: function () {
        },
      });
      headroom.init();
    });
    </script>

    
<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
     <script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>   <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script> 
        <link rel="stylesheet" href="../../../styles.css">
      </head>

  <body class="floating nav-fixed quarto-notebook quarto-light">
    <div id="quarto-embed-header" class="headroom fixed-top bg-primary">
      
      <a onclick="window.quartoBackToArticle(); return false;" class="btn btn-primary quarto-back-link"><i class="bi bi-caret-left"></i> Back to Article</a>
      <h6><i class="bi bi-journal-code"></i> A brief introduction to DPO</h6>

            <a href="../../../posts/LLM-From-Scratch/chapters/ch08.ipynb" class="btn btn-primary quarto-download-embed" download="ch08.ipynb">Download Notebook</a>
          </div>

     <div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">My Blogs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>    <div id="d04cb2b8-d87b-4c6b-a225-c630d758f68e" class="cell markdown">
<ul>
<li>This code notebook implements Direct Preference Optimization (DPO) from scratch and applies it to a large language model (LLM) to enhance its ability to generate responses that align more closely with user preferences</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [1]:</pre></div><div id="pxMGAf3bnVwn" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [2]:</pre></div><div id="edb3e145-fbaa-4bb3-9e95-186b4145087f" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3d449525-76cc-4124-ab30-a93c6a9623ee" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> importlib.metadata <span class="im">import</span> version</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>pkgs <span class="op">=</span> [</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"tiktoken"</span>,    <span class="co"># Tokenizer</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"torch"</span>,       <span class="co"># Deep learning library</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p <span class="kw">in</span> pkgs:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">}</span><span class="ss"> version: </span><span class="sc">{</span>version(p)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tiktoken version: 0.7.0
torch version: 2.3.1+cu121</code></pre>
</div>
</div></div>
<div id="49ec20a3-a26c-4f9b-8a33-bfd3d67860e2" class="cell markdown">
<p>&nbsp; ## A brief introduction to DPO</p>
</div>
<div id="17804afd-786b-4600-bad0-f5805454e3d6" class="cell markdown">
<ul>
<li>DPO, proposed in the paper <a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a>, is an alternative to reinforcement learning from human feedback (RLHF) used in finetuning large language models (LLMs)</li>
<li>DPO can be used to finetune (or align) the model to generate responses that better align with user expectations and instructions</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/1.webp" width="500px"></p>
<ul>
<li>In instruction finetuning, we train the LLM to generate correct answers given a prompt</li>
<li>However, in practice, there are multiple ways to give a correct answer, and correct answers can differ in style; for example, consider a technical and a more user-friendly response when asking an LLM to give recommendations when buying a laptop, as shown in the figure below</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/2.webp" width="700px"></p>
<ul>
<li>RLHF and DPO are methods that can be used to teach the LLM to prefer one answer style over the other, that is, aligning better with user preferences</li>
<li>The RLHF process, which requires training a separate reward model, is outlined below</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/4.webp" width="600px"></p>
</div>
<div id="9073622f-d537-42bf-8778-43c2adaa2191" class="cell markdown">
<ul>
<li>Compared to RLHF, DPO aims to simplify the process by optimizing models directly for user preferences without the need for complex reward modeling and policy optimization</li>
<li>In other words, DPO focuses on directly optimizing the model’s output to align with human preferences or specific objectives</li>
<li>Shown below is the main idea as an overview of how DPO works</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/5.webp?123" width="600px"></p>
</div>
<div id="c894134a-315c-453e-bbc1-387794b3f4d6" class="cell markdown">
<ul>
<li>The concrete equation to implement the DPO loss is shown below; we will revisit the equation when we implement it in Python further down in this code notebook</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123" width="600px"></p>
</div>
<div id="dd7491b5-f619-4501-ad39-2942de57c115" class="cell markdown">
<ul>
<li>In the equation above,
<ul>
<li>“expected value” <span class="math inline">\(\mathbb{E}\)</span> is statistics jargon and stands for the average or mean value of the random variable (the expression inside the brackets); optimizing <span class="math inline">\(-\mathbb{E}\)</span> aligns the model better with user preferences</li>
<li>The <span class="math inline">\(\pi_{\theta}\)</span> variable is the so-called policy (a term borrowed from reinforcement learning) and represents the LLM we want to optimize; <span class="math inline">\(\pi_{ref}\)</span> is a reference LLM, which is typically the original LLM before optimization (at the beginning of the training, <span class="math inline">\(\pi_{\theta}\)</span> and <span class="math inline">\(\pi_{ref}\)</span> are typically the same)</li>
<li><span class="math inline">\(\beta\)</span> is a hyperparameter to control the divergence between the <span class="math inline">\(\pi_{\theta}\)</span> and the reference model; increasing <span class="math inline">\(\beta\)</span> reduces the impact of the difference between <span class="math inline">\(\pi_{\theta}\)</span> and <span class="math inline">\(\pi_{ref}\)</span> in terms of their log probabilities on the overall loss function, thereby decreasing the divergence between the two models</li>
<li>the logistic sigmoid function, <span class="math inline">\(\sigma(\centerdot)\)</span> transforms the log-odds of the preferred and rejected responses (the terms inside the logistic sigmoid function) into a probability score</li>
</ul></li>
<li>To avoid bloating the code notebook with a more detailed discussion, I may write a separate standalone article with more details on these concepts in the future</li>
<li>In the meantime, if you are interested in comparing RLHF and DPO, please see the section <a href="https://magazine.sebastianraschka.com/i/142924793/rlhf-vs-direct-preference-optimization-dpo">2.2. RLHF vs Direct Preference Optimization (DPO)</a> in my article <a href="https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms">Tips for LLM Pretraining and Evaluating Reward Models</a></li>
</ul>
</div>
<div id="xqVAgsyQ6LuG" class="cell markdown">
<p>&nbsp; ## Preparing a preference dataset for DPO</p>
</div>
<div id="60b2195d-8734-469b-a52e-5031ca7ea6b1" class="cell markdown">
<ul>
<li>Let’s begin by loading and preparing the dataset, which may already answer a lot of the questions you might have before we revisit the DPO loss equation</li>
<li>Here, we work with a dataset that contains more polite and less polite responses to instruction prompts (concrete examples are shown in the next section)</li>
<li>The dataset was generated via the <a href="create-preference-data-ollama.ipynb">create-preference-data-ollama.ipynb</a> notebook</li>
</ul>
</div>
<div id="wHLB62Nj7haD" class="cell markdown">
<p>&nbsp; ## Loading a preference dataset</p>
</div>
<div id="13e09f99-1b18-4923-ba36-af46d8e3075f" class="cell markdown">
<ul>
<li>The dataset is a json file with 1100 entries:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [3]:</pre></div><div id="5266e66c-5ec0-45e6-a654-148971f6aee7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="04e8ee70-3076-441d-d2bf-7641da3d0c1d" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> download_and_load_file(file_path, url):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(file_path):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> requests.get(url, timeout<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        response.raise_for_status()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        text_data <span class="op">=</span> response.text</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(file_path, <span class="st">"w"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            <span class="bu">file</span>.write(text_data)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(file_path, <span class="st">"r"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            text_data <span class="op">=</span> <span class="bu">file</span>.read()</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> json.loads(text_data)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> <span class="st">"instruction-data-with-preference.json"</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> (</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch"</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"/main/ch07/04_preference-tuning-with-dpo/instruction-data-with-preference.json"</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> download_and_load_file(file_path, url)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of entries:"</span>, <span class="bu">len</span>(data))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of entries: 1100</code></pre>
</div>
</div></div>
<div id="725d2b9a-d6d2-46e2-89f8-5ab87e040e3b" class="cell markdown">
<ul>
<li>Let’s take a look at two example entries:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [4]:</pre></div><div id="5c11916f-9a26-4367-a16e-7b0c121a20a6" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="00a432cc-19b1-484f-80e2-e897ee5e4024" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pprint</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>pprint.pp(data[<span class="dv">50</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'instruction': 'Identify the correct spelling of the following word.',
 'input': 'Ocassion',
 'output': "The correct spelling is 'Occasion.'",
 'rejected': "The correct spelling is obviously 'Occasion.'",
 'chosen': "The correct spelling is 'Occasion.'"}</code></pre>
</div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [5]:</pre></div><div id="01ef804a-8c13-4a0b-9b2e-b65a4d0a870d" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="078cd643-83fb-4b42-ecf9-3256e8c9d239" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>pprint.pp(data[<span class="dv">999</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'instruction': "What is an antonym of 'complicated'?",
 'input': '',
 'output': "An antonym of 'complicated' is 'simple'.",
 'chosen': "A suitable antonym for 'complicated' would be 'simple'.",
 'rejected': "An antonym of 'complicated' is 'simple'."}</code></pre>
</div>
</div></div>
<div id="56db5697-a089-4b40-a1f3-e928e8018220" class="cell markdown">
<pre><code># This is formatted as code</code></pre>
<ul>
<li>As we can see above, the dataset consists of 5 keys:
<ul>
<li>The <code>'instruction'</code> and <code>'input'</code> that are used as LLM inputs</li>
<li>The <code>'output'</code> contains the response the model was trained on via the instruction finetuning step in chapter 7</li>
<li>the <code>'chosen'</code> and <code>'rejected'</code> entries are the entries we use for DPO; here <code>'chosen'</code> is the preferred response, and <code>'rejected'</code> is the dispreferred response</li>
</ul></li>
<li>The goal is to get the model to follow the style of the chosen over the rejected responses</li>
</ul>
</div>
<div id="86257468-a6ab-4ba3-9c9f-2fdc2c0cc284" class="cell markdown">
<ul>
<li>Below is a utility function that formats the model input by applying the Alpaca prompt style similar to chapter 7 (<a href="../01_main-chapter-code/ch07.ipynb">../01_main-chapter-code/ch07.ipynb</a>):</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [6]:</pre></div><div id="4564d55c-1c5d-46a6-b5e8-46ab568ad627" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_input(entry):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    instruction_text <span class="op">=</span> (</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Below is an instruction that describes a task. "</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Write a response that appropriately completes the request."</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="ch">\n\n</span><span class="ss">### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>entry[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    input_text <span class="op">=</span> <span class="ss">f"</span><span class="ch">\n\n</span><span class="ss">### Input:</span><span class="ch">\n</span><span class="sc">{</span>entry[<span class="st">'input'</span>]<span class="sc">}</span><span class="ss">"</span> <span class="cf">if</span> entry[<span class="st">"input"</span>] <span class="cf">else</span> <span class="st">""</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> instruction_text <span class="op">+</span> input_text</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [7]:</pre></div><div id="3f38b49f-63fd-48c5-bde8-a4717b7923ea" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9ad07c59-05b3-42ae-c5bc-68780aaf6780" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model_input <span class="op">=</span> format_input(data[<span class="dv">50</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_input)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Identify the correct spelling of the following word.

### Input:
Ocassion</code></pre>
</div>
</div></div>
<div id="7dd9e4c9-88a3-463a-8c16-c60ed7e6b51e" class="cell markdown">
<ul>
<li>Similarly, we can format the chosen and rejected responses using the Alpaca prompt style:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [8]:</pre></div><div id="8ad5831a-e936-44e5-a5cf-02953fe7d848" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2c0a0cbf-c13d-43cf-fcc1-a4585c21e66f" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>desired_response <span class="op">=</span> <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>data[<span class="dv">50</span>][<span class="st">'chosen'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(desired_response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>### Response:
The correct spelling is 'Occasion.'</code></pre>
</div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [9]:</pre></div><div id="fc0991f6-fef7-48ab-8dee-fbd2863f784c" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cd85406c-3470-48f8-9792-63f91affd50a" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>possible_response <span class="op">=</span> <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>data[<span class="dv">50</span>][<span class="st">'rejected'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(possible_response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>### Response:
The correct spelling is obviously 'Occasion.'</code></pre>
</div>
</div></div>
<div id="6G3j2Q987t_g" class="cell markdown">
<p>&nbsp; ## Creating training, validation, and test splits</p>
</div>
<div id="53ce2b1e-32d7-414c-8e6b-01f21a2488c2" class="cell markdown">
<ul>
<li>Next, we divide the dataset into 3 subsets, 85% training data, 5% validation data, and 10% test data:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [10]:</pre></div><div id="36c7b919-8531-4e33-aebf-aaf8e6dbcfbd" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>train_portion <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(data) <span class="op">*</span> <span class="fl">0.85</span>)  <span class="co"># 85% for training</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>test_portion <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(data) <span class="op">*</span> <span class="fl">0.1</span>)    <span class="co"># 10% for testing</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>val_portion <span class="op">=</span> <span class="bu">len</span>(data) <span class="op">-</span> train_portion <span class="op">-</span> test_portion  <span class="co"># Remaining 5% for validation</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> data[:train_portion]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> data[train_portion:train_portion <span class="op">+</span> test_portion]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>val_data <span class="op">=</span> data[train_portion <span class="op">+</span> test_portion:]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [11]:</pre></div><div id="831a6c1b-119b-4622-9862-87f1db36e066" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8e017483-1a75-4336-9540-ac6a69104e27" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set length:"</span>, <span class="bu">len</span>(train_data))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Validation set length:"</span>, <span class="bu">len</span>(val_data))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test set length:"</span>, <span class="bu">len</span>(test_data))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set length: 935
Validation set length: 55
Test set length: 110</code></pre>
</div>
</div></div>
<div id="c07d09f7-66af-49ed-8b9e-484f46e6a68d" class="cell markdown">
<p>&nbsp; ## Developing a <code>PreferenceDataset</code> class and batch processing function</p>
</div>
<div id="86101174-00c8-485d-8273-d086d5311926" class="cell markdown">
<ul>
<li>In this section, we rewrite the <code>InstructionDataset</code> class from chapter 7 (<a href="../01_main-chapter-code/ch07.ipynb">../01_main-chapter-code/ch07.ipynb</a>) for DPO</li>
<li>This means that instead of focusing on single output sequences (responses), we modify the dataset class to return pairs of responses where one is preferred (“chosen”) over the other (“rejected”)</li>
<li>Overall, the <code>PreferenceDataset</code> is almost identical to the <code>InstructionDataset</code> used in chapter 7:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [12]:</pre></div><div id="db08ad74-6dd4-4e40-b1e5-bc5f037d3d27" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PreferenceDataset(Dataset):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, tokenizer):</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pre-tokenize texts</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoded_texts <span class="op">=</span> []</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> entry <span class="kw">in</span> data:</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>            prompt <span class="op">=</span> format_input(entry)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            rejected_response <span class="op">=</span> entry[<span class="st">"rejected"</span>]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            chosen_response <span class="op">=</span> entry[<span class="st">"chosen"</span>]</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>            prompt_tokens <span class="op">=</span> tokenizer.encode(prompt)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            chosen_full_text <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">### Response:</span><span class="ch">\n</span><span class="sc">{</span>chosen_response<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            rejected_full_text <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>prompt<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">### Response:</span><span class="ch">\n</span><span class="sc">{</span>rejected_response<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>            chosen_full_tokens <span class="op">=</span> tokenizer.encode(chosen_full_text)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>            rejected_full_tokens <span class="op">=</span> tokenizer.encode(rejected_full_text)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.encoded_texts.append({</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">"prompt"</span>: prompt_tokens,</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">"chosen"</span>: chosen_full_tokens,</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">"rejected"</span>: rejected_full_tokens,</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.encoded_texts[index]</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="2325d183-75b9-400a-80ac-0b8d2f526561" class="cell markdown">
<ul>
<li>Along with an updated <code>PreferenceDataset</code> class, we also need an updated batch collation function that we use to pad the sequences in each batch to an equal length so that we can assemble them in batches</li>
<li>I added comments to the code below to illustrate the process; however, it might be easiest to understand how it works by looking at the example inputs and outputs further below:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [13]:</pre></div><div id="8d3a43a6-7704-4bff-9bbc-a38632374f30" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> custom_collate_fn(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    batch,</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    pad_token_id<span class="op">=</span><span class="dv">50256</span>,</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    allowed_max_length<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    mask_prompt_tokens<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span><span class="st">"cpu"</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize lists to hold batch data</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    batch_data <span class="op">=</span> {</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prompt"</span>: [],</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"chosen"</span>: [],</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rejected"</span>: [],</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rejected_mask"</span>: [],</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"chosen_mask"</span>: []</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine the longest sequence to set a common padding length</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    max_length_common <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> batch:</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> [<span class="st">"chosen"</span>, <span class="st">"rejected"</span>]:</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>            current_max <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(item[key])<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> item <span class="kw">in</span> batch)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>            max_length_common <span class="op">=</span> <span class="bu">max</span>(max_length_common, current_max)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process each item in the batch</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> batch:</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> torch.tensor(item[<span class="st">"prompt"</span>])</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>        batch_data[<span class="st">"prompt"</span>].append(prompt)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> [<span class="st">"chosen"</span>, <span class="st">"rejected"</span>]:</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Adjust padding according to the common maximum length</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            sequence <span class="op">=</span> item[key]</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>            padded <span class="op">=</span> sequence <span class="op">+</span> [pad_token_id] <span class="op">*</span> (max_length_common <span class="op">-</span> <span class="bu">len</span>(sequence))</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> torch.ones(<span class="bu">len</span>(padded)).<span class="bu">bool</span>()</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Set mask for all padding tokens to False</span></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>            mask[<span class="bu">len</span>(sequence):] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Set mask for all input tokens to False</span></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># +2 sets the 2 newline ("\n") tokens before "### Response" to False</span></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> mask_prompt_tokens:</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>                mask[:prompt.shape[<span class="dv">0</span>]<span class="op">+</span><span class="dv">2</span>] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>            batch_data[key].append(torch.tensor(padded))</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>            batch_data[<span class="ss">f"</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">_mask"</span>].append(mask)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Final processing</span></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> [<span class="st">"chosen"</span>, <span class="st">"rejected"</span>, <span class="st">"chosen_mask"</span>, <span class="st">"rejected_mask"</span>]:</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stack all sequences into a tensor for the given key</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>        tensor_stack <span class="op">=</span> torch.stack(batch_data[key])</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Optionally truncate to maximum sequence length</span></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> allowed_max_length <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>            tensor_stack <span class="op">=</span> tensor_stack[:, :allowed_max_length]</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move to the specified device</span></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>        batch_data[key] <span class="op">=</span> tensor_stack.to(device)</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch_data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="76f3744b-9bb0-4f1e-b66b-cff35ad8fd9f" class="cell markdown">
<ul>
<li>Before we start using the custom collate function, let’s make version of it with some of its function arguments prefilled:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [14]:</pre></div><div id="d3cc137c-7ed7-4758-a518-cc4071b2817a" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="598e9def-9768-441a-f886-01f6ba6e250b" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Device:"</span>, device)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>customized_collate_fn <span class="op">=</span> partial(</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    custom_collate_fn,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,            <span class="co"># Put the data directly on a GPU if available</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    mask_prompt_tokens<span class="op">=</span><span class="va">True</span>,  <span class="co"># This is optional</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    allowed_max_length<span class="op">=</span><span class="dv">1024</span>   <span class="co"># The supported context length of the model</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Device: cuda</code></pre>
</div>
</div></div>
<div id="5d29e996-e267-4348-bc1d-4ac6b725cf6a" class="cell markdown">
<ul>
<li>Now, let’s see the <code>customized_collate_fn</code> in action and apply it to some sample data from our preference dataset; for this, we take the first two entries:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [15]:</pre></div><div id="1171057d-2a0f-48ff-bad6-4917a072f0f5" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3db3eee8-db29-4ff6-8078-6577a05d953a" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>example_data <span class="op">=</span> data[:<span class="dv">2</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> example_data:</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    pprint.pp(i)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
{'instruction': 'Evaluate the following phrase by transforming it into the '
                'spelling given.',
 'input': 'freind --&gt; friend',
 'output': 'The spelling of the given phrase "freind" is incorrect, the '
           'correct spelling is "friend".',
 'rejected': 'The spelling of the given phrase "freind" is flat out wrong, get '
             'it together, the correct spelling is "friend".',
 'chosen': 'The spelling of the given phrase "freind" is incorrect, the '
           'correct spelling is "friend".'}

{'instruction': 'Edit the following sentence for grammar.',
 'input': 'He go to the park every day.',
 'output': 'He goes to the park every day.',
 'rejected': 'He goes to the stupid park every single day.',
 'chosen': 'He goes to the park every day.'}</code></pre>
</div>
</div></div>
<div id="8f1436cc-fbe5-4581-89d8-1992b5f04042" class="cell markdown">
<ul>
<li>Next, let’s instantiate an <code>example_dataset</code> and use a PyTorch <code>DataLoader</code> to create an <code>example_dataloader</code> that mimics the data loader we will use for the model training later:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [16]:</pre></div><div id="db327575-c34b-4fea-b3c7-e30569c9be78" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tiktoken</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> tiktoken.get_encoding(<span class="st">"gpt2"</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>example_dataset <span class="op">=</span> PreferenceDataset(example_data, tokenizer)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>example_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    example_dataset,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    collate_fn<span class="op">=</span>customized_collate_fn,</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="43a446b7-7037-4d9a-9f14-b4ee0f6f37af" class="cell markdown">
<ul>
<li>The dataset has the following keys:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [17]:</pre></div><div id="87ed4cf9-d70a-4bc7-b676-67e76ed3ee10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fa724d65-b0e1-4239-8090-9263135ad199" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> example_dataloader:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"batch.keys:"</span>, batch.keys())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>batch.keys: dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])</code></pre>
</div>
</div></div>
<div id="5bda3193-8c68-478c-98d8-0d9d880e7077" class="cell markdown">
<ul>
<li>The prompts are a list of tensors, where each tensor contains the token IDs for a given example; since we selected a batch size of 2, we have two lists of token ID tensors here:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [18]:</pre></div><div id="468995ce-2906-498f-ac99-0a3f80d13d12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7f3df961-fcb5-4e49-9b0c-c99447c67cc1" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>batch[<span class="st">"prompt"</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>[tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,
           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,
         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,
           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,
         21017, 23412,    25,   198, 19503,   521, 14610,  1545]),
 tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,
           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,
         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,
            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,
           262,  3952,   790,  1110,    13])]</code></pre>
</div>
</div></div>
<div id="89cadebe-2516-4ae0-a71f-a8a623f2e1da" class="cell markdown">
<ul>
<li>We don’t really need the responses for training; what we need to feed to the model during training are the <code>"chosen"</code> and <code>"rejected"</code> entries</li>
<li>The <code>"chosen"</code> and <code>"rejected"</code> response entries are padded so that we can stack them as tensors; similar to the prompts, these response texts are encoded into token IDs:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [19]:</pre></div><div id="e8f49c56-3989-4fe9-81ac-6bb3cce1a5b8" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ccc0bd06-6e85-4ee9-893b-d985f26a835d" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>batch[<span class="st">"chosen"</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,
           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,
         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,
           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,
         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,
         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,
           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,
           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,
         50256],
        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,
           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,
         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,
            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,
           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,
           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256]], device='cuda:0')</code></pre>
</div>
</div></div>
<div id="35a4cd6d-b2ad-45a6-b00a-ba5b720be4ea" class="cell markdown">
<ul>
<li>The token IDs above represent the model inputs, but in this format, they are hard to interpret for us humans</li>
<li>So, let’s implement a small utility function to convert them back into text so that we can inspect and interpret them more easily:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [20]:</pre></div><div id="52ea54ba-32cb-4ecb-b38b-923f42fd4615" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decode_tokens_from_batch(token_ids, tokenizer):</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    ids_in_python_list <span class="op">=</span> token_ids.flatten().tolist()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer.decode(ids_in_python_list)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="bc9dd0ce-1fd4-419c-833f-ea5a1f8d800d" class="cell markdown">
<ul>
<li>Let’s apply the <code>decode_tokens_from_batch</code> utility function to the first prompt entry in the batch:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [21]:</pre></div><div id="55ee481e-3e2c-4ff6-b614-8cb18eb16a41" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="17ddec15-a09d-45b5-b1e8-600cd59a9600" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> decode_tokens_from_batch(</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    token_ids<span class="op">=</span>batch[<span class="st">"prompt"</span>][<span class="dv">0</span>],  <span class="co"># [0] for the first entry in the batch</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Evaluate the following phrase by transforming it into the spelling given.

### Input:
freind --&gt; friend</code></pre>
</div>
</div></div>
<div id="637b95c4-d5c2-4492-9d19-a45b090eee7e" class="cell markdown">
<ul>
<li>As we can see above, the prompt was correctly formatted; let’s now do the same for the <code>"chosen"</code> response:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [22]:</pre></div><div id="33a24f20-5ec3-4a89-b57a-52e997163d07" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e04366ee-3719-4b07-fcef-6e9dddc06310" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> decode_tokens_from_batch(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    token_ids<span class="op">=</span>batch[<span class="st">"chosen"</span>][<span class="dv">0</span>],</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Evaluate the following phrase by transforming it into the spelling given.

### Input:
freind --&gt; friend

### Response:
The spelling of the given phrase "freind" is incorrect, the correct spelling is "friend".&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;</code></pre>
</div>
</div></div>
<div id="ac9fbdbd-1cff-401f-8e6c-cd98c134c0f2" class="cell markdown">
<ul>
<li>As we can see above, similar to instruction finetuning, the response that is passed to the model during training also contains the input prompt</li>
<li>Also note that we included <code>&lt;|endoftext|&gt;</code> tokens as padding tokens, which are necessary so that we can extend the responses to a similar length to stack them as a batch</li>
<li>Don’t worry; the <code>&lt;|endoftext|&gt;</code> tokens will be ignored in the loss later so that they won’t affect the training outcome</li>
<li>Let’s now also inspect the corresponding rejected response:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [23]:</pre></div><div id="db382be5-c727-4299-8597-c05424ba9308" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="edbd8c4a-0528-4361-aeba-9b3c3bbde33b" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> decode_tokens_from_batch(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    token_ids<span class="op">=</span>batch[<span class="st">"rejected"</span>][<span class="dv">0</span>],</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Evaluate the following phrase by transforming it into the spelling given.

### Input:
freind --&gt; friend

### Response:
The spelling of the given phrase "freind" is flat out wrong, get it together, the correct spelling is "friend".&lt;|endoftext|&gt;</code></pre>
</div>
</div></div>
<div id="715dc968-aa64-4388-b577-7c295831bdcf" class="cell markdown">
<ul>
<li>In this case, as we can see above, the rejected response is a more impolite version of the chosen response (we don’t want the model to generate impolite responses)</li>
<li>Lastly, let’s talk about the data masks: if you took a closer look at our custom collate function we implemented above, we created a <code>"chosen_mask"</code> and a <code>"rejected_mask"</code> for each dataset entry</li>
<li>The masks have the same shape as the response entries, as shown below for the <code>"chosen"</code> entry:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [24]:</pre></div><div id="5c324eab-cf1d-4071-b3ba-797d8ec4d1da" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="742a5742-1bc0-4f74-9eb9-cbf81f936ecb" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"chosen inputs:"</span>, batch[<span class="st">"chosen"</span>][<span class="dv">0</span>].shape)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"chosen mask:  "</span>, batch[<span class="st">"chosen_mask"</span>][<span class="dv">0</span>].shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>chosen inputs: torch.Size([81])
chosen mask:   torch.Size([81])</code></pre>
</div>
</div></div>
<div id="880e95f7-cfc3-4f5f-be5e-c279fba5f674" class="cell markdown">
<ul>
<li>The contents of these masks are boolean (<code>True</code> and <code>False</code>) values:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [25]:</pre></div><div id="da75b550-5da4-4292-9a7e-a05b842bdcb7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e5f012c3-33ba-4e6b-aa55-3e331865218f" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>batch[<span class="st">"chosen_mask"</span>][<span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False, False, False, False, False,
        False], device='cuda:0')</code></pre>
</div>
</div></div>
<div id="0e67b862-4430-4c99-9157-90955dde29b6" class="cell markdown">
<ul>
<li>The <code>True</code> values denote token IDs that correspond to the actual response</li>
<li>the <code>False</code> tokens correspond to token IDs that correspond to either prompt tokens (if we set <code>mask_prompt_tokens=True</code> in the <code>customized_collate_fn</code> function, which we previously did) or padding tokens</li>
<li>Hence, we can use the mask as a selection mask to select only the token IDs that correspond to the response, that is, stripping all prompt and padding tokens, as we can see below:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [26]:</pre></div><div id="1114c6fe-524b-401c-b9fe-02260e6f0541" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6d99af1d-940a-4012-c5d9-21d463a66e40" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> decode_tokens_from_batch(</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    token_ids<span class="op">=</span>batch[<span class="st">"chosen"</span>][<span class="dv">0</span>][batch[<span class="st">"chosen_mask"</span>][<span class="dv">0</span>]],</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>### Response:
The spelling of the given phrase "freind" is incorrect, the correct spelling is "friend".</code></pre>
</div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [27]:</pre></div><div id="a89f83a4-d16e-40d2-ba43-bd410affd967" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1d439c7e-c079-4594-d02a-fa83a3cb275d" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> decode_tokens_from_batch(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    token_ids<span class="op">=</span>batch[<span class="st">"rejected"</span>][<span class="dv">0</span>][batch[<span class="st">"rejected_mask"</span>][<span class="dv">0</span>]],</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>### Response:
The spelling of the given phrase "freind" is flat out wrong, get it together, the correct spelling is "friend".</code></pre>
</div>
</div></div>
<div id="e525287f-137c-4d71-94ae-cfd6db7b057c" class="cell markdown">
<ul>
<li>We will make use of this mask to ignore prompt and padding tokens when computing the DPO loss later</li>
</ul>
</div>
<div id="jbafhM_R8z5q" class="cell markdown">
<p>&nbsp; ## Creating training, validation, and test set data loaders</p>
</div>
<div id="b3c29eb8-d1b9-4abe-a155-52b3270d759a" class="cell markdown">
<ul>
<li>Above, we worked with a small example subsets from the preference dataset for illustration purposes</li>
<li>Let’s now create the actual training, validation, and test set data loaders</li>
<li>This process is identical to creating the data loaders in the pretraining and instruction finetuning chapters and thus should be self-explanatory</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [28]:</pre></div><div id="5c0068bf-bda0-4d9e-9f79-2fc4b94cbd1c" class="cell" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>num_workers <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> PreferenceDataset(train_data, tokenizer)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    train_dataset,</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    collate_fn<span class="op">=</span>customized_collate_fn,</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    drop_last<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span>num_workers</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [29]:</pre></div><div id="2f4a257b-6835-4194-abe2-5831d6a44885" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> PreferenceDataset(val_data, tokenizer)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    val_dataset,</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    collate_fn<span class="op">=</span>customized_collate_fn,</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    drop_last<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span>num_workers</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> PreferenceDataset(test_data, tokenizer)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    test_dataset,</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    collate_fn<span class="op">=</span>customized_collate_fn,</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    drop_last<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span>num_workers</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="1fe1ba19-a6d5-4a77-8283-7a17d7ec06e2" class="cell markdown">
<ul>
<li>Let’s iterate through the data loader and take a look at the dataset shapes:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [30]:</pre></div><div id="80d61f15-facb-4eb8-a9be-6427887d24b2" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="dacd3bdf-f069-4b36-da2c-d6c1c6cc5405" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train loader:"</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">"chosen"</span>].shape,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">"rejected"</span>].shape,</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train loader:
torch.Size([8, 77]) torch.Size([8, 77])
torch.Size([8, 81]) torch.Size([8, 81])
torch.Size([8, 94]) torch.Size([8, 94])
torch.Size([8, 75]) torch.Size([8, 75])
torch.Size([8, 75]) torch.Size([8, 75])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 99]) torch.Size([8, 99])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 67]) torch.Size([8, 67])
torch.Size([8, 88]) torch.Size([8, 88])
torch.Size([8, 65]) torch.Size([8, 65])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 80]) torch.Size([8, 80])
torch.Size([8, 97]) torch.Size([8, 97])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 89]) torch.Size([8, 89])
torch.Size([8, 75]) torch.Size([8, 75])
torch.Size([8, 69]) torch.Size([8, 69])
torch.Size([8, 84]) torch.Size([8, 84])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 101]) torch.Size([8, 101])
torch.Size([8, 87]) torch.Size([8, 87])
torch.Size([8, 73]) torch.Size([8, 73])
torch.Size([8, 69]) torch.Size([8, 69])
torch.Size([8, 80]) torch.Size([8, 80])
torch.Size([8, 68]) torch.Size([8, 68])
torch.Size([8, 73]) torch.Size([8, 73])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 91]) torch.Size([8, 91])
torch.Size([8, 78]) torch.Size([8, 78])
torch.Size([8, 78]) torch.Size([8, 78])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 84]) torch.Size([8, 84])
torch.Size([8, 92]) torch.Size([8, 92])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 66]) torch.Size([8, 66])
torch.Size([8, 73]) torch.Size([8, 73])
torch.Size([8, 73]) torch.Size([8, 73])
torch.Size([8, 78]) torch.Size([8, 78])
torch.Size([8, 66]) torch.Size([8, 66])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 100]) torch.Size([8, 100])
torch.Size([8, 77]) torch.Size([8, 77])
torch.Size([8, 92]) torch.Size([8, 92])
torch.Size([8, 93]) torch.Size([8, 93])
torch.Size([8, 115]) torch.Size([8, 115])
torch.Size([8, 81]) torch.Size([8, 81])
torch.Size([8, 95]) torch.Size([8, 95])
torch.Size([8, 81]) torch.Size([8, 81])
torch.Size([8, 94]) torch.Size([8, 94])
torch.Size([8, 70]) torch.Size([8, 70])
torch.Size([8, 89]) torch.Size([8, 89])
torch.Size([8, 90]) torch.Size([8, 90])
torch.Size([8, 70]) torch.Size([8, 70])
torch.Size([8, 85]) torch.Size([8, 85])
torch.Size([8, 65]) torch.Size([8, 65])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 72]) torch.Size([8, 72])
torch.Size([8, 84]) torch.Size([8, 84])
torch.Size([8, 84]) torch.Size([8, 84])
torch.Size([8, 65]) torch.Size([8, 65])
torch.Size([8, 63]) torch.Size([8, 63])
torch.Size([8, 74]) torch.Size([8, 74])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 93]) torch.Size([8, 93])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 99]) torch.Size([8, 99])
torch.Size([8, 81]) torch.Size([8, 81])
torch.Size([8, 77]) torch.Size([8, 77])
torch.Size([8, 74]) torch.Size([8, 74])
torch.Size([8, 75]) torch.Size([8, 75])
torch.Size([8, 73]) torch.Size([8, 73])
torch.Size([8, 87]) torch.Size([8, 87])
torch.Size([8, 80]) torch.Size([8, 80])
torch.Size([8, 75]) torch.Size([8, 75])
torch.Size([8, 81]) torch.Size([8, 81])
torch.Size([8, 86]) torch.Size([8, 86])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 63]) torch.Size([8, 63])
torch.Size([8, 82]) torch.Size([8, 82])
torch.Size([8, 68]) torch.Size([8, 68])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 68]) torch.Size([8, 68])
torch.Size([8, 97]) torch.Size([8, 97])
torch.Size([8, 72]) torch.Size([8, 72])
torch.Size([8, 85]) torch.Size([8, 85])
torch.Size([8, 67]) torch.Size([8, 67])
torch.Size([8, 85]) torch.Size([8, 85])
torch.Size([8, 87]) torch.Size([8, 87])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 74]) torch.Size([8, 74])
torch.Size([8, 92]) torch.Size([8, 92])
torch.Size([8, 85]) torch.Size([8, 85])
torch.Size([8, 72]) torch.Size([8, 72])
torch.Size([8, 93]) torch.Size([8, 93])
torch.Size([8, 82]) torch.Size([8, 82])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 93]) torch.Size([8, 93])
torch.Size([8, 80]) torch.Size([8, 80])
torch.Size([8, 87]) torch.Size([8, 87])
torch.Size([8, 69]) torch.Size([8, 69])
torch.Size([8, 90]) torch.Size([8, 90])
torch.Size([8, 99]) torch.Size([8, 99])
torch.Size([8, 104]) torch.Size([8, 104])
torch.Size([8, 101]) torch.Size([8, 101])
torch.Size([8, 98]) torch.Size([8, 98])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 71]) torch.Size([8, 71])
torch.Size([8, 76]) torch.Size([8, 76])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 79]) torch.Size([8, 79])
torch.Size([8, 67]) torch.Size([8, 67])
torch.Size([8, 84]) torch.Size([8, 84])
torch.Size([8, 78]) torch.Size([8, 78])
torch.Size([8, 85]) torch.Size([8, 85])
torch.Size([8, 70]) torch.Size([8, 70])</code></pre>
</div>
</div></div>
<div id="7ff958a6-5e61-49f5-9a97-360aa34e3758" class="cell markdown">
<ul>
<li>Each row shows the shape of the <code>"chosen"</code> and <code>"rejected"</code> entries in each batch</li>
<li>Since we applied padding on a batch-by-batch basis, each row has a different shape</li>
<li>This is for efficiency reasons because it would be inefficient to pad all samples to the longest sample in the whole dataset</li>
</ul>
</div>
<div id="29cb0543-1142-4374-8825-3384e20c6ac0" class="cell markdown">
<p>&nbsp; ## Loading a finetuned LLM for DPO alignment</p>
</div>
<div id="22b08881-b769-4b26-8153-5ec0e8573ed2" class="cell markdown">
<ul>
<li>LLM alignment steps, such as RLHF or DPO, assume that we already have an instruction-finetuned model</li>
<li>This section contains minimal code to load the model that was instruction finetuned and saved in chapter 7 (via <a href="../01_main-chapter-code/ch07.ipynb">../01_main-chapter-code/ch07.ipynb</a>)</li>
<li>Make sure you run the chapter 7 code first to create the instruction-finetuned model before you proceed</li>
<li>The code below will copy the instruction-finetuned model into the current directory:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [31]:</pre></div><div id="b3c6d82b-63f7-459a-b901-7125ab225e56" class="cell" data-execution_count="31">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>finetuned_model_path <span class="op">=</span> Path(<span class="st">"gpt2-medium355M-sft.pth"</span>)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> finetuned_model_path.exists():</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Try finding the model checkpoint locally:</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>    relative_path <span class="op">=</span> Path(<span class="st">".."</span>) <span class="op">/</span> <span class="st">"01_main-chapter-code"</span> <span class="op">/</span> finetuned_model_path</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> relative_path.exists():</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>        shutil.copy(relative_path, <span class="st">"."</span>)</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If this notebook is run on Google Colab, get it from a Google Drive folder</span></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">"COLAB_GPU"</span> <span class="kw">in</span> os.environ <span class="kw">or</span> <span class="st">"COLAB_TPU_ADDR"</span> <span class="kw">in</span> os.environ:</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>        drive.mount(<span class="st">"/content/drive"</span>)</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>        google_drive_path <span class="op">=</span> <span class="st">"/content/drive/My Drive/Books/LLMs-From-Scratch/ch07/colab/gpt2-medium355M-sft.pth"</span>  <span class="co"># Readers need to adjust this path</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>        shutil.copy(google_drive_path, <span class="st">"."</span>)</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Could not find '</span><span class="sc">{</span>finetuned_model_path<span class="sc">}</span><span class="ss">'.</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Run the `ch07.ipynb` notebook to finetune and save the finetuned model."</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>        )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="71c8585e-4569-4033-84a7-3903d0e8aaf8" class="cell markdown">
<ul>
<li>Next, we reuse the basic configuration from previous chapters to load the model weights:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [32]:</pre></div><div id="a8333fee-e7fe-4f8c-9411-8c1db6252d98" class="cell" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> previous_chapters <span class="im">import</span> GPTModel</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co"># If the `previous_chapters.py` file is not available locally,</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="co"># you can import it from the `llms-from-scratch` PyPI package.</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="co"># E.g.,</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="co"># from llms_from_scratch.ch04 import GPTModel</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>BASE_CONFIG <span class="op">=</span> {</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"vocab_size"</span>: <span class="dv">50257</span>,     <span class="co"># Vocabulary size</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"context_length"</span>: <span class="dv">1024</span>,  <span class="co"># Context length</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"drop_rate"</span>: <span class="fl">0.0</span>,        <span class="co"># Dropout rate</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"qkv_bias"</span>: <span class="va">True</span>         <span class="co"># Query-key-value bias</span></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>model_configs <span class="op">=</span> {</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gpt2-small (124M)"</span>: {<span class="st">"emb_dim"</span>: <span class="dv">768</span>, <span class="st">"n_layers"</span>: <span class="dv">12</span>, <span class="st">"n_heads"</span>: <span class="dv">12</span>},</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gpt2-medium (355M)"</span>: {<span class="st">"emb_dim"</span>: <span class="dv">1024</span>, <span class="st">"n_layers"</span>: <span class="dv">24</span>, <span class="st">"n_heads"</span>: <span class="dv">16</span>},</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gpt2-large (774M)"</span>: {<span class="st">"emb_dim"</span>: <span class="dv">1280</span>, <span class="st">"n_layers"</span>: <span class="dv">36</span>, <span class="st">"n_heads"</span>: <span class="dv">20</span>},</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gpt2-xl (1558M)"</span>: {<span class="st">"emb_dim"</span>: <span class="dv">1600</span>, <span class="st">"n_layers"</span>: <span class="dv">48</span>, <span class="st">"n_heads"</span>: <span class="dv">25</span>},</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>CHOOSE_MODEL <span class="op">=</span> <span class="st">"gpt2-medium (355M)"</span></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a>BASE_CONFIG.update(model_configs[CHOOSE_MODEL])</span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPTModel(BASE_CONFIG)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [33]:</pre></div><div id="c2821403-605c-4071-a4ff-e23f4c9a11fd" class="cell" data-execution_count="33">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>    torch.load(</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"gpt2-medium355M-sft.pth"</span>,</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>        map_location<span class="op">=</span>torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>        weights_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="61863bec-bd42-4194-b994-645bfe2df8be" class="cell markdown">
<ul>
<li>Before training the loaded model with DPO, let’s make sure that the finetuned model was saved and loaded correctly by trying it out on some sample data:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [34]:</pre></div><div id="4357aec5-0db2-4d73-b37b-539cd8fa80a3" class="cell" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""Below is an instruction that describes a task. Write a response</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="st">that appropriately completes the request.</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="st">### Instruction:</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="st">Convert the active sentence to passive: 'The chef cooks the meal every day.'</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [35]:</pre></div><div id="541e7988-38d3-47f6-bd52-9da6564479fa" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="278f7ddf-37c2-4c3a-d069-c510ef6f8d7a" data-execution_count="35">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> previous_chapters <span class="im">import</span> (</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    generate,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    text_to_token_ids,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    token_ids_to_text</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively:</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co"># from llms_from_scratch.ch05 (</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     generate,</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     text_to_token_ids,</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co">#     token_ids_to_text</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>token_ids <span class="op">=</span> generate(</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    idx<span class="op">=</span>text_to_token_ids(prompt, tokenizer),</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">35</span>,</span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>    context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>    eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response
that appropriately completes the request.

### Instruction:
Convert the active sentence to passive: 'The chef cooks the meal every day.'

### Response:
The meal is cooked every day by the chef.</code></pre>
</div>
</div></div>
<div id="be87ed19-fded-4e56-8585-6c7c0367b354" class="cell markdown">
<ul>
<li>As we can see above, the model gives a reasonable and correct response</li>
<li>As explained in chapter 7, in practice, we would clean up the response to only return the response text with the prompt and prompt style removed (similar to what you are familiar with from ChatGPT, for example):</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [36]:</pre></div><div id="0c30c4e2-af84-4ab4-95d0-9641e32c1e7f" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="70192bbe-fdf6-43eb-c673-f573f8c70156" data-execution_count="36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_response(response_text, input_text):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response_text[<span class="bu">len</span>(input_text):].replace(<span class="st">"### Response:"</span>, <span class="st">""</span>).strip()</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> extract_response(response, prompt)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>The meal is cooked every day by the chef.</code></pre>
</div>
</div></div>
<div id="80442cb9-83b1-46b8-bad0-7d44297ca52d" class="cell markdown">
<ul>
<li>Now, we are almost ready to get to the DPO part</li>
<li>As mentioned at the beginning of this notebook, DPO works with two LLMs: a policy model (the LLM that we want to optimize) and a reference model (the original model that we keep unchanged)</li>
<li>Below, we rename the <code>model</code> as <code>policy_model</code> and instantiate a second instance of the model we refer to as the <code>reference_model</code></li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [37]:</pre></div><div id="5d88cc3a-312e-4b29-bc6d-de8354c1eb9f" class="cell" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>policy_model <span class="op">=</span> model</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>reference_model <span class="op">=</span> GPTModel(BASE_CONFIG)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>reference_model.load_state_dict(</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    torch.load(</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"gpt2-medium355M-sft.pth"</span>,</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>        map_location<span class="op">=</span>torch.device(<span class="st">"cpu"</span>),</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>        weights_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>reference_model.<span class="bu">eval</span>()</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>policy_model.to(device)</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>reference_model.to(device)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="9c6c1469-0038-4914-8aa5-15b1f81877cc" class="cell markdown">
<p>&nbsp; ## Coding the DPO Loss Function</p>
</div>
<div id="75dbe60c-e4ce-413e-beec-22eff0237d11" class="cell markdown">
<ul>
<li>After we took care of the model loading and dataset preparation in the previous sections, we can now get to the fun part and code the DPO loss</li>
<li>Note that the DPO loss code below is based on the method proposed in the <a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a> paper</li>
<li>For reference, the core DPO equation is shown again below:</li>
</ul>
<p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123" width="800px"></p>
<ul>
<li>In the equation above,
<ul>
<li>“expected value” <span class="math inline">\(\mathbb{E}\)</span> is statistics jargon and stands for the average or mean value of the random variable (the expression inside the brackets); optimizing <span class="math inline">\(-\mathbb{E}\)</span> aligns the model better with user preferences</li>
<li>The <span class="math inline">\(\pi_{\theta}\)</span> variable is the so-called policy (a term borrowed from reinforcement learning) and represents the LLM we want to optimize; <span class="math inline">\(\pi_{ref}\)</span> is a reference LLM, which is typically the original LLM before optimization (at the beginning of the training, <span class="math inline">\(\pi_{\theta}\)</span> and <span class="math inline">\(\pi_{ref}\)</span> are typically the same)</li>
<li><span class="math inline">\(\beta\)</span> is a hyperparameter to control the divergence between the <span class="math inline">\(\pi_{\theta}\)</span> and the reference model; increasing <span class="math inline">\(\beta\)</span> increases the impact of the difference between <span class="math inline">\(\pi_{\theta}\)</span> and <span class="math inline">\(\pi_{ref}\)</span> in terms of their log probabilities on the overall loss function, thereby increasing the divergence between the two models</li>
<li>the logistic sigmoid function, <span class="math inline">\(\sigma(\centerdot)\)</span> transforms the log-odds of the preferred and rejected responses (the terms inside the logistic sigmoid function) into a probability score</li>
</ul></li>
<li>In code, we can implement the DPO loss as follows:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [38]:</pre></div><div id="38CsrrwJIZiV" class="cell" data-execution_count="38">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_dpo_loss(</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>      model_chosen_logprobs,</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>      model_rejected_logprobs,</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>      reference_chosen_logprobs,</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>      reference_rejected_logprobs,</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>      beta<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the DPO loss for a batch of policy and reference model log probabilities.</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a><span class="co">        policy_chosen_logprobs: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)</span></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="co">        policy_rejected_logprobs: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="co">        reference_chosen_logprobs: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a><span class="co">        reference_rejected_logprobs: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)</span></span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a><span class="co">        beta: Temperature parameter for the DPO loss; typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -&gt; 0.</span></span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a><span class="co">        A tuple of three tensors: (loss, chosen_rewards, rejected_rewards).</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    model_logratios <span class="op">=</span> model_chosen_logprobs <span class="op">-</span> model_rejected_logprobs</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>    reference_logratios <span class="op">=</span> reference_chosen_logprobs <span class="op">-</span> reference_rejected_logprobs</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> model_logratios <span class="op">-</span> reference_logratios</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># DPO (Eq. 7 of https://arxiv.org/pdf/2305.18290.pdf)</span></span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> <span class="op">-</span>F.logsigmoid(beta <span class="op">*</span> logits)</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optional values to track progress during training</span></span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>    chosen_rewards <span class="op">=</span> (model_chosen_logprobs <span class="op">-</span> reference_chosen_logprobs).detach()</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>    rejected_rewards <span class="op">=</span> (model_rejected_logprobs <span class="op">-</span> reference_rejected_logprobs).detach()</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-34"><a href="#cb62-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .mean() to average over the samples in the batch</span></span>
<span id="cb62-35"><a href="#cb62-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="693be65b-38fc-4d18-bf53-a260a15436e1" class="cell markdown">
<ul>
<li><p>If you are familiar with logarithms, note that we have the general relationship <span class="math inline">\(\log\left(\frac{a}{b}\right) = \log a - \log b\)</span>, which we applied in the code above</p></li>
<li><p>Keeping this in mind, let’s go through some of the steps (we will calculate the <code>logprobs</code> using a separate function later)</p></li>
<li><p>Let’s start with the lines</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>model_logratios <span class="op">=</span> model_chosen_logprobs <span class="op">-</span> model_rejected_logprobs</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>reference_logratios <span class="op">=</span> reference_chosen_logprobs <span class="op">-</span> reference_rejected_logprobs</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>These lines above calculate the difference in log probabilities (logits) for the chosen and rejected samples for both the policy model and the reference model (this is due to <span class="math inline">\(\log\left(\frac{a}{b}\right) = \log a - \log b\)</span>):</p></li>
</ul>
<p><span class="math display">\[\log \left( \frac{\pi_\theta (y_w \mid x)}{\pi_\theta (y_l \mid x)} \right) \quad \text{and} \quad \log \left( \frac{\pi_{\text{ref}}(y_w \mid x)}{\pi_{\text{ref}}(y_l \mid x)} \right)\]</span></p>
</div>
<div id="5458d217-e0ad-40a5-925c-507a8fcf5795" class="cell markdown">
<ul>
<li>Next, the code <code>logits = model_logratios - reference_logratios</code> computes the difference between the model’s log ratios and the reference model’s log ratios, i.e.,</li>
</ul>
<p><span class="math display">\[\beta \log \left( \frac{\pi_\theta (y_w \mid x)}{\pi_{\text{ref}} (y_w \mid x)} \right)
- \beta \log \left( \frac{\pi_\theta (y_l \mid x)}{\pi_{\text{ref}} (y_l \mid x)} \right)\]</span></p>
</div>
<div id="f18e3e36-f5f1-407f-b662-4c20a0ac0354" class="cell markdown">
<ul>
<li>Finally, <code>losses = -F.logsigmoid(beta * logits)</code> calculates the loss using the log-sigmoid function; in the original equation, the term inside the expectation is</li>
</ul>
<p><span class="math display">\[\log \sigma \left( \beta \log \left( \frac{\pi_\theta (y_w \mid x)}{\pi_{\text{ref}} (y_w \mid x)} \right)
- \beta \log \left( \frac{\pi_\theta (y_l \mid x)}{\pi_{\text{ref}} (y_l \mid x)} \right) \right)\]</span></p>
</div>
<div id="00a6f92d-7d64-41fe-bcaa-2bddd46027e1" class="cell markdown">
<ul>
<li>Above, we assumed that the log probabilities were already computed; let’s now define a <code>compute_logprobs</code> function that we can use to compute these log probabilities that were passed into the <code>compute_dpo_loss</code> function above, that is, the values <span class="math inline">\(\pi_\theta (y_w \mid x)\)</span>, <span class="math inline">\({\pi_\theta (y_l \mid x)}\)</span>, and so forth:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [39]:</pre></div><div id="71e6507b-d2e2-4469-86b9-f057b08b5df9" class="cell" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_logprobs(logits, labels, selection_mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute log probabilities.</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co">      logits: Tensor of shape (batch_size, num_tokens, vocab_size)</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">      labels: Tensor of shape (batch_size, num_tokens)</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="co">      selection_mask: Tensor for shape (batch_size, num_tokens)</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="co">      mean_log_prob: Mean log probability excluding padding tokens.</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Labels are the inputs shifted by one</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> labels[:, <span class="dv">1</span>:].clone()</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Truncate logits to match the labels num_tokens</span></span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> logits[:, :<span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>    log_probs <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gather the log probabilities for the actual labels</span></span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>    selected_log_probs <span class="op">=</span> torch.gather(</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">input</span><span class="op">=</span>log_probs,</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>        dim<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>        index<span class="op">=</span>labels.unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a>    ).squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> selection_mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> selection_mask[:, <span class="dv">1</span>:].clone()</span>
<span id="cb64-31"><a href="#cb64-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-32"><a href="#cb64-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the mask to filter out padding tokens</span></span>
<span id="cb64-33"><a href="#cb64-33" aria-hidden="true" tabindex="-1"></a>        selected_log_probs <span class="op">=</span> selected_log_probs <span class="op">*</span> mask</span>
<span id="cb64-34"><a href="#cb64-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-35"><a href="#cb64-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the average log probability excluding padding tokens</span></span>
<span id="cb64-36"><a href="#cb64-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This averages over the tokens, so the shape is (batch_size,)</span></span>
<span id="cb64-37"><a href="#cb64-37" aria-hidden="true" tabindex="-1"></a>        avg_log_prob <span class="op">=</span> selected_log_probs.<span class="bu">sum</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">/</span> mask.<span class="bu">sum</span>(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb64-38"><a href="#cb64-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-39"><a href="#cb64-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> avg_log_prob</span>
<span id="cb64-40"><a href="#cb64-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-41"><a href="#cb64-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb64-42"><a href="#cb64-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> selected_log_probs.mean(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="cf6a71ac-3fcc-44a4-befc-1c56bbd378d7" class="cell markdown">
<ul>
<li>Note that this function above might look a bit intimidating at first due to the <code>torch.gather</code> function, but it’s pretty similar to what happens under the hood in PyTorch’s <code>cross_entropy</code> function</li>
<li>For example, consider the following example:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [40]:</pre></div><div id="59873470-464d-4be2-860f-cbb7ac2d80ba" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8f7b47d4-73fe-4605-c17d-ad6cfd909a9b" data-execution_count="40">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample data</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor(</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    [[<span class="fl">2.0</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>],</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.5</span>, <span class="fl">2.5</span>, <span class="fl">0.3</span>]])  <span class="co"># Shape: (2, 3)</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> torch.tensor([<span class="dv">0</span>, <span class="dv">2</span>])  <span class="co"># Shape: (2,)</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual loss using torch.gather</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>log_softmax_logits <span class="op">=</span> F.log_softmax(logits, dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Shape: (2, 3)</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>selected_log_probs <span class="op">=</span> torch.gather(</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span><span class="op">=</span>log_softmax_logits,</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>targets.unsqueeze(<span class="dv">1</span>), <span class="co"># Shape 2, 1</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>).squeeze(<span class="dv">1</span>)  <span class="co"># Shape: (2,)</span></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>manual_loss <span class="op">=</span> <span class="op">-</span>selected_log_probs.mean()  <span class="co"># Averaging over the batch</span></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a><span class="co"># PyTorch loss</span></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>cross_entropy_loss <span class="op">=</span> F.cross_entropy(logits, targets)</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(manual_loss, cross_entropy_loss)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(1.4185) tensor(1.4185)</code></pre>
</div>
</div></div>
<div id="f86d7add-f7ff-4a87-9193-7878c42bf0e7" class="cell markdown">
<ul>
<li>So, above, we can see that the two implementations are equivalent, but let’s narrow down a bit further to the <code>torch.gather</code> mechanics</li>
<li>Consider the following two tensors:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [41]:</pre></div><div id="508db6ba-cc40-479f-a996-2250cf862388" class="cell" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.tensor(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  [[<span class="fl">1.</span>, <span class="fl">2.</span>,],</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>   [<span class="fl">3.</span>, <span class="fl">4.</span>]]</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> torch.tensor(</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>  [[<span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>   [<span class="dv">0</span>, <span class="dv">1</span>]]</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="821cbf45-8fbb-47b7-bae8-6c3271e36979" class="cell markdown">
<ul>
<li>Above, <code>t</code> is a tensor we want to select from, and <code>m</code> is a mask to specify how we want to select</li>
<li>For instance, since <code>m</code> contains <code>[1, 1]</code> n the first row, it will select two times the value of <code>t</code> in index position <code>1</code>, which is the value 2.</li>
<li>The second row of <code>m</code>, <code>[0, 1]</code>, selects index positions 0 and 1 in the second row or <code>t</code>, which are <code>3.</code> and <code>4.</code></li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [42]:</pre></div><div id="4fdN5q1YPAbM" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e935e8ad-1519-4c4b-dbff-65adae0a15a4" data-execution_count="42">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>torch.gather(<span class="bu">input</span><span class="op">=</span>t, dim<span class="op">=-</span><span class="dv">1</span>, index<span class="op">=</span>m)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[2., 2.],
        [3., 4.]])</code></pre>
</div>
</div></div>
<div id="d10eeaf4-f24b-4e79-916a-abedf74fe4a3" class="cell markdown">
<ul>
<li>In other words, <code>torch.gather</code> is a selection function</li>
<li>When we computed the loss earlier, we used it to retrieve the log probabilities corresponding to the correct token in the 50,257-token vocabulary</li>
<li>The “correct” tokens are the tokens given in the response entry</li>
</ul>
</div>
<div id="d5d10a43-ee5b-47ed-9d55-ddd96e66cf0b" class="cell markdown">
<ul>
<li>Regarding the <code>compute_logprobs</code> function above, we use <code>torch.gather</code> here because it gives us a bit more control than <code>cross_entropy</code>, but is, in essence, a similar idea</li>
<li>The <code>selection_mask</code> we use there is to optionally ignore prompt and padding tokens</li>
<li>We can then use the <code>compute_logprobs</code> function as follows to compute the inputs for the <code>compute_dpo_loss</code> loss function</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [43]:</pre></div><div id="dfa7a4db-eba0-47d8-ad6d-7b5e7676e318" class="cell" data-execution_count="43">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_dpo_loss_batch(batch, policy_model, reference_model, beta):</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the DPO loss on an input batch"""</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># where policy_model(batch["chosen"]) are the logits</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    policy_chosen_log_probas <span class="op">=</span> compute_logprobs(</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>        logits<span class="op">=</span>policy_model(batch[<span class="st">"chosen"</span>]),</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>        labels<span class="op">=</span>batch[<span class="st">"chosen"</span>],</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>        selection_mask<span class="op">=</span>batch[<span class="st">"chosen_mask"</span>]</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    policy_rejected_log_probas <span class="op">=</span> compute_logprobs(</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>        logits<span class="op">=</span>policy_model(batch[<span class="st">"rejected"</span>]),</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>        labels<span class="op">=</span>batch[<span class="st">"rejected"</span>],</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>        selection_mask<span class="op">=</span>batch[<span class="st">"rejected_mask"</span>]</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>        ref_chosen_log_probas <span class="op">=</span> compute_logprobs(</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>            logits<span class="op">=</span>reference_model(batch[<span class="st">"chosen"</span>]),</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>batch[<span class="st">"chosen"</span>],</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>            selection_mask<span class="op">=</span>batch[<span class="st">"chosen_mask"</span>]</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a>        ref_rejected_log_probas <span class="op">=</span> compute_logprobs(</span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>            logits<span class="op">=</span>reference_model(batch[<span class="st">"rejected"</span>]),</span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>batch[<span class="st">"rejected"</span>],</span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a>            selection_mask<span class="op">=</span>batch[<span class="st">"rejected_mask"</span>]</span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a>    loss, chosen_rewards, rejected_rewards <span class="op">=</span> compute_dpo_loss(</span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>        model_chosen_logprobs<span class="op">=</span>policy_chosen_log_probas,</span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>        model_rejected_logprobs<span class="op">=</span>policy_rejected_log_probas,</span>
<span id="cb70-30"><a href="#cb70-30" aria-hidden="true" tabindex="-1"></a>        reference_chosen_logprobs<span class="op">=</span>ref_chosen_log_probas,</span>
<span id="cb70-31"><a href="#cb70-31" aria-hidden="true" tabindex="-1"></a>        reference_rejected_logprobs<span class="op">=</span>ref_rejected_log_probas,</span>
<span id="cb70-32"><a href="#cb70-32" aria-hidden="true" tabindex="-1"></a>        beta<span class="op">=</span>beta</span>
<span id="cb70-33"><a href="#cb70-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb70-34"><a href="#cb70-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss, chosen_rewards, rejected_rewards</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="b28caafb-f378-4332-a142-3e0f9ef67fbb" class="cell markdown">
<ul>
<li>The above function works for a single batch, for example:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [44]:</pre></div><div id="dd74fcc4-4280-41e9-9a22-838e85c84ee4" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="65a70828-7dd2-4f72-ffec-45aeaf8afad0" data-execution_count="44">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_dpo_loss_batch(batch, policy_model, reference_model, beta<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(loss)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>(tensor(0.6931, device='cuda:0'), tensor(0., device='cuda:0'), tensor(0., device='cuda:0'))</code></pre>
</div>
</div></div>
<div id="b17429cd-2a00-41c8-9f16-38b1c9a5179f" class="cell markdown">
<ul>
<li>Below, we extend this function to work for a specified <code>num_batches</code> in a data loader:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [45]:</pre></div><div id="682e9ad5-c5de-4d1b-9e93-3918bf5d5302" class="cell" data-execution_count="45">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_dpo_loss_loader(data_loader, policy_model, reference_model, beta, num_batches<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Apply compute_dpo_loss_batch to a whole data loader"""</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>    total_loss, total_chosen_rewards, total_rejected_rewards <span class="op">=</span> <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">0.</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(data_loader) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">float</span>(<span class="st">"nan"</span>)</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> num_batches <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>        num_batches <span class="op">=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reduce the number of batches to match the total number of batches in the data loader</span></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if num_batches exceeds the number of batches in the data loader</span></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>        num_batches <span class="op">=</span> <span class="bu">min</span>(num_batches, <span class="bu">len</span>(data_loader))</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&lt;</span> num_batches:</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>            loss, chosen_rewards, rejected_rewards <span class="op">=</span> compute_dpo_loss_batch(</span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>                batch<span class="op">=</span>batch,</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>                policy_model<span class="op">=</span>policy_model,</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>                reference_model<span class="op">=</span>reference_model,</span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>                beta<span class="op">=</span>beta</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>            total_chosen_rewards <span class="op">+=</span> chosen_rewards.item()</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>            total_rejected_rewards <span class="op">+=</span> rejected_rewards.item()</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate average</span></span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">/=</span> num_batches</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>    total_chosen_rewards <span class="op">/=</span> num_batches</span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>    total_rejected_rewards <span class="op">/=</span> num_batches</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss, total_chosen_rewards, total_rejected_rewards</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="852e4c09-d285-44d5-be12-d29769950cb6" class="cell markdown">
<ul>
<li>Why a specified <code>num_batches</code>? That’s purely for efficiency reasons (because calculating the loss on the whole dataset each time would slow down the training significantly)</li>
</ul>
</div>
<div id="2cca95b7-18fe-4076-9138-f70f21607b8c" class="cell markdown">
<ul>
<li>Lastly, we define a convenience function for our training function later; this <code>evaluate_dpo_loss_loader</code> function computes the DPO loss and rewards for both the training and validation loader for logging purposes:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [46]:</pre></div><div id="c3d214ec-49ba-4bf0-ac80-f90fa0d832e9" class="cell" data-execution_count="46">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the DPO loss for the training and validation dataset"""</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    policy_model.<span class="bu">eval</span>()</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>        train_loss, train_chosen_rewards, train_rejected_rewards <span class="op">=</span> compute_dpo_loss_loader(</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>            data_loader<span class="op">=</span>train_loader,</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>            policy_model<span class="op">=</span>policy_model,</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>            reference_model<span class="op">=</span>reference_model,</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>            beta<span class="op">=</span>beta,</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>            num_batches<span class="op">=</span>eval_iter</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>        val_loss, val_chosen_rewards, val_rejected_rewards <span class="op">=</span> compute_dpo_loss_loader(</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>            data_loader<span class="op">=</span>val_loader,</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>            policy_model<span class="op">=</span>policy_model,</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>            reference_model<span class="op">=</span>reference_model,</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>            beta<span class="op">=</span>beta,</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>            num_batches<span class="op">=</span>eval_iter</span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> {</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_loss"</span>: train_loss,</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_chosen_reward"</span>: train_chosen_rewards,</span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_rejected_reward"</span>: train_rejected_rewards,</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_loss"</span>: val_loss,</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_chosen_reward"</span>: val_chosen_rewards,</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_rejected_reward"</span>: val_rejected_rewards</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>    policy_model.train()</span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div id="6e95ed92-6743-4f13-8b91-0fbf2e540de1" class="cell markdown">
<ul>
<li>In this section, we covered a lot of ground as a brief recap:
<ul>
<li>The flow is: compute <code>logits</code> via the models <span class="math inline">\(\rightarrow\)</span> <code>compute_logprobs</code> from logits <span class="math inline">\(\rightarrow\)</span> compute <code>compute_dpo_loss</code> from log probabilities</li>
<li>we have the <code>compute_dpo_loss_batch</code> function that facilitates the process above</li>
<li>the <code>compute_dpo_loss_loader</code> utility function applies the <code>compute_dpo_loss_batch</code> function to a data loader</li>
<li>the <code>evaluate_dpo_loss_loader</code> function applies the <code>compute_dpo_loss_batch</code> to both the training and validation set data loaders for logging purposes</li>
</ul></li>
</ul>
</div>
<div id="cb8a8f18-536e-4d83-a0d0-ac518a85f157" class="cell markdown">
<p>&nbsp; ## Training the model</p>
</div>
<div id="4b11d63d-3ddc-4070-9b2b-5ca0edb08d0c" class="cell markdown">
<ul>
<li>After setting up the DPO loss functions in the previous section, we can now finally train the model</li>
<li>Note that this training function is the same one we used for pretraining and instruction finetuning, with minor differences:</li>
<li>we swap the cross-entropy loss with our new DPO loss function</li>
<li>we also track the rewards and reward margins, which are commonly used in RLHF and DPO contexts to track the training progress</li>
</ul>
</div>
<div id="820d4904-f819-4d62-bfb4-85cf28863683" class="cell markdown">
<ul>
<li>Before we start the training, let’s print the initial losses and rewards:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [47]:</pre></div><div id="f90d9325-77b2-417f-88ff-0a5174889413" class="cell" data-execution_count="47">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> previous_chapters <span class="im">import</span> generate_and_print_sample</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively:</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co"># from llms_from_scratch.ch04 import generate_text_simple</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model_dpo_simple(</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>    policy_model, reference_model, train_loader, val_loader,</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>    optimizer, num_epochs, beta,</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>    eval_freq, eval_iter, start_context, tokenizer</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize lists to track losses and tokens seen</span></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>    tracking <span class="op">=</span> {</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_losses"</span>: [],</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_chosen_rewards"</span>: [],</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_rejected_rewards"</span>: [],</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_losses"</span>: [],</span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_chosen_rewards"</span>: [],</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_rejected_rewards"</span>: [],</span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tokens_seen"</span>: []</span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>    tokens_seen, global_step <span class="op">=</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span></span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Main training loop</span></span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a>        policy_model.train()  <span class="co"># Set model to training mode</span></span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()  <span class="co"># Reset loss gradients from previous batch iteration</span></span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a>            loss, chosen_rewards, rejected_rewards <span class="op">=</span> compute_dpo_loss_batch(</span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a>                batch<span class="op">=</span>batch,</span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a>                policy_model<span class="op">=</span>policy_model,</span>
<span id="cb75-35"><a href="#cb75-35" aria-hidden="true" tabindex="-1"></a>                reference_model<span class="op">=</span>reference_model,</span>
<span id="cb75-36"><a href="#cb75-36" aria-hidden="true" tabindex="-1"></a>                beta<span class="op">=</span>beta</span>
<span id="cb75-37"><a href="#cb75-37" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb75-38"><a href="#cb75-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-39"><a href="#cb75-39" aria-hidden="true" tabindex="-1"></a>            loss.backward()  <span class="co"># Calculate loss gradients</span></span>
<span id="cb75-40"><a href="#cb75-40" aria-hidden="true" tabindex="-1"></a>            optimizer.step()  <span class="co"># Update model weights using loss gradients</span></span>
<span id="cb75-41"><a href="#cb75-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-42"><a href="#cb75-42" aria-hidden="true" tabindex="-1"></a>            tokens_seen <span class="op">+=</span> batch[<span class="st">"chosen"</span>].numel()</span>
<span id="cb75-43"><a href="#cb75-43" aria-hidden="true" tabindex="-1"></a>            global_step <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb75-44"><a href="#cb75-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-45"><a href="#cb75-45" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Optional evaluation step</span></span>
<span id="cb75-46"><a href="#cb75-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> global_step <span class="op">%</span> eval_freq <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb75-47"><a href="#cb75-47" aria-hidden="true" tabindex="-1"></a>                res <span class="op">=</span> evaluate_dpo_loss_loader(</span>
<span id="cb75-48"><a href="#cb75-48" aria-hidden="true" tabindex="-1"></a>                    policy_model<span class="op">=</span>policy_model,</span>
<span id="cb75-49"><a href="#cb75-49" aria-hidden="true" tabindex="-1"></a>                    reference_model<span class="op">=</span>reference_model,</span>
<span id="cb75-50"><a href="#cb75-50" aria-hidden="true" tabindex="-1"></a>                    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb75-51"><a href="#cb75-51" aria-hidden="true" tabindex="-1"></a>                    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb75-52"><a href="#cb75-52" aria-hidden="true" tabindex="-1"></a>                    beta<span class="op">=</span>beta,</span>
<span id="cb75-53"><a href="#cb75-53" aria-hidden="true" tabindex="-1"></a>                    eval_iter<span class="op">=</span>eval_iter</span>
<span id="cb75-54"><a href="#cb75-54" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb75-55"><a href="#cb75-55" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"train_losses"</span>].append(res[<span class="st">"train_loss"</span>])</span>
<span id="cb75-56"><a href="#cb75-56" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"train_chosen_rewards"</span>].append(res[<span class="st">"train_chosen_reward"</span>])</span>
<span id="cb75-57"><a href="#cb75-57" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"train_rejected_rewards"</span>].append(res[<span class="st">"train_rejected_reward"</span>])</span>
<span id="cb75-58"><a href="#cb75-58" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"val_losses"</span>].append(res[<span class="st">"val_loss"</span>])</span>
<span id="cb75-59"><a href="#cb75-59" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"val_chosen_rewards"</span>].append(res[<span class="st">"val_chosen_reward"</span>])</span>
<span id="cb75-60"><a href="#cb75-60" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"val_rejected_rewards"</span>].append(res[<span class="st">"val_rejected_reward"</span>])</span>
<span id="cb75-61"><a href="#cb75-61" aria-hidden="true" tabindex="-1"></a>                tracking[<span class="st">"tokens_seen"</span>].append(tokens_seen)</span>
<span id="cb75-62"><a href="#cb75-62" aria-hidden="true" tabindex="-1"></a>                train_reward_margin <span class="op">=</span> res[<span class="st">"train_chosen_reward"</span>] <span class="op">-</span> res[<span class="st">"train_rejected_reward"</span>]</span>
<span id="cb75-63"><a href="#cb75-63" aria-hidden="true" tabindex="-1"></a>                val_reward_margin <span class="op">=</span> res[<span class="st">"val_chosen_reward"</span>] <span class="op">-</span> res[<span class="st">"val_rejected_reward"</span>]</span>
<span id="cb75-64"><a href="#cb75-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-65"><a href="#cb75-65" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(</span>
<span id="cb75-66"><a href="#cb75-66" aria-hidden="true" tabindex="-1"></a>                    <span class="ss">f"Ep </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> (Step </span><span class="sc">{</span>global_step<span class="sc">:06d}</span><span class="ss">): "</span></span>
<span id="cb75-67"><a href="#cb75-67" aria-hidden="true" tabindex="-1"></a>                    <span class="ss">f"Train loss </span><span class="sc">{</span>res[<span class="st">'train_loss'</span>]<span class="sc">:.3f}</span><span class="ss">, Val loss </span><span class="sc">{</span>res[<span class="st">'val_loss'</span>]<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb75-68"><a href="#cb75-68" aria-hidden="true" tabindex="-1"></a>                    <span class="ss">f"Train reward margins </span><span class="sc">{</span>train_reward_margin<span class="sc">:.3f}</span><span class="ss">, "</span></span>
<span id="cb75-69"><a href="#cb75-69" aria-hidden="true" tabindex="-1"></a>                    <span class="ss">f"Val reward margins </span><span class="sc">{</span>val_reward_margin<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb75-70"><a href="#cb75-70" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb75-71"><a href="#cb75-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-72"><a href="#cb75-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print a sample text after each epoch</span></span>
<span id="cb75-73"><a href="#cb75-73" aria-hidden="true" tabindex="-1"></a>        generate_and_print_sample(</span>
<span id="cb75-74"><a href="#cb75-74" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span>model,</span>
<span id="cb75-75"><a href="#cb75-75" aria-hidden="true" tabindex="-1"></a>            tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb75-76"><a href="#cb75-76" aria-hidden="true" tabindex="-1"></a>            device<span class="op">=</span>loss.device,</span>
<span id="cb75-77"><a href="#cb75-77" aria-hidden="true" tabindex="-1"></a>            start_context<span class="op">=</span>start_context</span>
<span id="cb75-78"><a href="#cb75-78" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb75-79"><a href="#cb75-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-80"><a href="#cb75-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tracking</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [48]:</pre></div><div id="d53210c5-6d9c-46b0-af22-ee875c2806c5" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8b1d2b39-16c5-4b99-e920-5b33d3c0f34d" data-execution_count="48">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>) <span class="co"># For reproducibility due to the shuffling in the data loader</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> evaluate_dpo_loss_loader(</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    policy_model<span class="op">=</span>policy_model,</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>    reference_model<span class="op">=</span>reference_model,</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    beta<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>    eval_iter<span class="op">=</span><span class="dv">5</span></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training loss:"</span>, res[<span class="st">"train_loss"</span>])</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Validation loss:"</span>, res[<span class="st">"val_loss"</span>])</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train reward margin:"</span>, res[<span class="st">"train_chosen_reward"</span>] <span class="op">-</span> res[<span class="st">"train_rejected_reward"</span>])</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Val reward margin:"</span>, res[<span class="st">"val_chosen_reward"</span>] <span class="op">-</span> res[<span class="st">"val_rejected_reward"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training loss: 0.6931471824645996
Validation loss: 0.6931471824645996
Train reward margin: 0.0
Val reward margin: 0.0</code></pre>
</div>
</div></div>
<div id="4a006e91-df94-43ca-8025-1ba791e37bc4" class="cell markdown">
<ul>
<li>Also, let’s take a look at some of the initial model responses (the first 3 examples in the validation set):</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [49]:</pre></div><div id="q4Ro9DrBa7zH" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b974d4bd-b92a-4a2a-bb7a-5a2a0d1eca11" data-execution_count="49">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> entry <span class="kw">in</span> val_data[:<span class="dv">3</span>]:</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>    input_text <span class="op">=</span> format_input(entry)</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>    token_ids <span class="op">=</span> generate(</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model,</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">=</span>text_to_token_ids(input_text, tokenizer).to(device),</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>        context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>        eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>    generated_text <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>    response_text <span class="op">=</span> (</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>        generated_text[<span class="bu">len</span>(input_text):]</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>        .replace(<span class="st">"### Response:"</span>, <span class="st">""</span>)</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a>        .strip()</span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(input_text)</span>
<span id="cb78-23"><a href="#cb78-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Correct response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>entry[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Model response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>response_text<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">-------------------------------------</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Convert the active sentence to passive: 'The chef cooks the meal every day.'

Correct response:
&gt;&gt; The meal is cooked by the chef every day.

Model response:
&gt;&gt; The meal is cooked every day by the chef.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Classify an input string as either a noun or a verb.

### Input:
Dance

Correct response:
&gt;&gt; 'Dance' can be classified as a verb.

Model response:
&gt;&gt; "Dance" can be classified as a verb.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Rewrite the sentence using a metaphor.

### Input:
The book is very interesting.

Correct response:
&gt;&gt; The book is a page-turner.

Model response:
&gt;&gt; The book is a treat.

-------------------------------------
</code></pre>
</div>
</div></div>
<div id="ac2386ae-5c4c-448e-bfbf-4ec0604b171e" class="cell markdown">
<ul>
<li>Above, we see the original model responses</li>
<li>Note that the goal of DPO is to induce slight style changes; this means we want the model to generate similar but slightly more polite responses</li>
<li>Before we execute the following code cell that starts the training, here are a few notes about some of the settings:</li>
<li>we are only passing the parameters of the policy model into the <code>AdamW</code> optimizer; that’s the model we want to optimize (we don’t want to modify the reference model)</li>
<li>we only train for 1 epoch; that’s because DPO is very prone to collapse (the loss might improve, but the model will start generating nonsensical texts)</li>
<li>in DPO, it’s best to use a very small learning rate</li>
<li>the beta value can be increased from 0.1 to 0.5 to reduce the effect of DPO (we use 0.1 here to make the results more noticeable)</li>
<li>The training takes about 2 minutes on an A100 GPU, but it can also be trained in 4 minutes on a smaller L4 GPU; training on a M3 MacBook Air takes about 30 minutes</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [50]:</pre></div><div id="54b739be-871e-4c97-bf14-ffd2c58e1311" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d98b08b0-c325-411e-a1a4-05e7403f0345" data-execution_count="50">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(policy_model.parameters(), lr<span class="op">=</span><span class="fl">5e-6</span>, weight_decay<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>tracking <span class="op">=</span> train_model_dpo_simple(</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>    policy_model<span class="op">=</span>policy_model,</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>    reference_model<span class="op">=</span>reference_model,</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer,</span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>    num_epochs<span class="op">=</span>num_epochs,</span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a>    beta<span class="op">=</span><span class="fl">0.1</span>, <span class="co"># value between 0.1 and 0.5</span></span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>    eval_freq<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>    eval_iter<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a>    start_context<span class="op">=</span>format_input(val_data[<span class="dv">2</span>]),</span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer</span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a>execution_time_minutes <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">/</span> <span class="dv">60</span></span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training completed in </span><span class="sc">{</span>execution_time_minutes<span class="sc">:.2f}</span><span class="ss"> minutes."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ep 1 (Step 000000): Train loss 0.692, Val loss 0.693, Train reward margins 0.019, Val reward margins 0.009
Ep 1 (Step 000005): Train loss 0.690, Val loss 0.691, Train reward margins 0.070, Val reward margins 0.052
Ep 1 (Step 000010): Train loss 0.687, Val loss 0.688, Train reward margins 0.126, Val reward margins 0.108
Ep 1 (Step 000015): Train loss 0.676, Val loss 0.685, Train reward margins 0.362, Val reward margins 0.173
Ep 1 (Step 000020): Train loss 0.676, Val loss 0.680, Train reward margins 0.351, Val reward margins 0.264
Ep 1 (Step 000025): Train loss 0.666, Val loss 0.676, Train reward margins 0.564, Val reward margins 0.359
Ep 1 (Step 000030): Train loss 0.672, Val loss 0.672, Train reward margins 0.456, Val reward margins 0.441
Ep 1 (Step 000035): Train loss 0.663, Val loss 0.669, Train reward margins 0.658, Val reward margins 0.511
Ep 1 (Step 000040): Train loss 0.666, Val loss 0.666, Train reward margins 0.597, Val reward margins 0.574
Ep 1 (Step 000045): Train loss 0.648, Val loss 0.662, Train reward margins 0.982, Val reward margins 0.660
Ep 1 (Step 000050): Train loss 0.648, Val loss 0.659, Train reward margins 0.993, Val reward margins 0.734
Ep 1 (Step 000055): Train loss 0.647, Val loss 0.656, Train reward margins 1.014, Val reward margins 0.799
Ep 1 (Step 000060): Train loss 0.652, Val loss 0.653, Train reward margins 0.893, Val reward margins 0.870
Ep 1 (Step 000065): Train loss 0.631, Val loss 0.650, Train reward margins 1.361, Val reward margins 0.948
Ep 1 (Step 000070): Train loss 0.618, Val loss 0.646, Train reward margins 1.699, Val reward margins 1.038
Ep 1 (Step 000075): Train loss 0.617, Val loss 0.642, Train reward margins 1.733, Val reward margins 1.121
Ep 1 (Step 000080): Train loss 0.592, Val loss 0.639, Train reward margins 2.333, Val reward margins 1.194
Ep 1 (Step 000085): Train loss 0.610, Val loss 0.636, Train reward margins 1.907, Val reward margins 1.275
Ep 1 (Step 000090): Train loss 0.650, Val loss 0.633, Train reward margins 0.964, Val reward margins 1.353
Ep 1 (Step 000095): Train loss 0.607, Val loss 0.630, Train reward margins 1.962, Val reward margins 1.423
Ep 1 (Step 000100): Train loss 0.600, Val loss 0.627, Train reward margins 2.127, Val reward margins 1.500
Ep 1 (Step 000105): Train loss 0.590, Val loss 0.624, Train reward margins 2.458, Val reward margins 1.564
Ep 1 (Step 000110): Train loss 0.607, Val loss 0.622, Train reward margins 1.976, Val reward margins 1.621
Ep 1 (Step 000115): Train loss 0.621, Val loss 0.620, Train reward margins 1.605, Val reward margins 1.682
Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a metaphor.  ### Input: The book is very interesting.  ### Response: The book is a treat.&lt;|endoftext|&gt;The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The assignment was written by the student.  ### Response
Training completed in 1.69 minutes.</code></pre>
</div>
</div></div>
<div id="eba8ea88-8771-4eb9-855d-2fe1ca2dc2fa" class="cell markdown">
<ul>
<li>As we can see based on the tracked results above, the loss improves</li>
<li>Also, the reward margins, which is the difference between the rewards of the chosen and the rejected responses, improve, which is a good sign</li>
<li>Let’s take a more concrete look at these results in the next section</li>
</ul>
</div>
<div id="11e23989-92bd-4ac2-a4bc-65d4c7ac334e" class="cell markdown">
<p>&nbsp; ## Analyzing the results</p>
</div>
<div id="66d7d5fe-c617-45cb-8ea9-ddc7baa22654" class="cell markdown">
<ul>
<li>Let’s begin analyzing the results by plotting the DPO loss:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [51]:</pre></div><div id="8ddcc66f-cd7c-4f46-96ea-af919ea1a199" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:307}}" data-outputid="c7164b26-8d32-41d1-8c6a-ab835d58d4c5" data-execution_count="51">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> previous_chapters <span class="im">import</span> plot_losses</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternatively:</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="co"># from llms_from_scratch.ch05 import plot_losses</span></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>epochs_tensor <span class="op">=</span> torch.linspace(<span class="dv">0</span>, num_epochs, <span class="bu">len</span>(tracking[<span class="st">"train_losses"</span>]))</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>plot_losses(</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    epochs_seen<span class="op">=</span>epochs_tensor,</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>    tokens_seen<span class="op">=</span>tracking[<span class="st">"tokens_seen"</span>],</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    train_losses<span class="op">=</span>tracking[<span class="st">"train_losses"</span>],</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>    val_losses<span class="op">=</span>tracking[<span class="st">"val_losses"</span>],</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"loss"</span></span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="">
<figure class="figure">
<p class=""><img src="ch08_files/figure-html/cell-52-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div></div>
<div id="7f8bc233-895f-46d5-8e01-202b991cd60c" class="cell markdown">
<ul>
<li>As we can see above, the loss continues to improve, which is a good sign</li>
<li>Based on the downward slope, one might be tempted to train the model a bit further (and readers are encouraged to try this), but note that DPO is prone to collapse, where the model may start generating nonsensical responses</li>
<li>Next, let’s take a look at the reward margins:</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [52]:</pre></div><div id="dmbq6ruuf0Cl" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:307}}" data-outputid="c2886c16-57da-41bd-c9f0-e936da9d9e4d" data-execution_count="52">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>train_reward_margins <span class="op">=</span> [i<span class="op">-</span>j <span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">zip</span>(tracking[<span class="st">"train_chosen_rewards"</span>], tracking[<span class="st">"train_rejected_rewards"</span>])]</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>val_reward_margins <span class="op">=</span> [i<span class="op">-</span>j <span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">zip</span>(tracking[<span class="st">"val_chosen_rewards"</span>], tracking[<span class="st">"val_rejected_rewards"</span>])]</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>plot_losses(</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    epochs_seen<span class="op">=</span>epochs_tensor,</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    tokens_seen<span class="op">=</span>tracking[<span class="st">"tokens_seen"</span>],</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>    train_losses<span class="op">=</span>train_reward_margins,</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    val_losses<span class="op">=</span>val_reward_margins,</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"reward margins"</span></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="">
<figure class="figure">
<p class=""><img src="ch08_files/figure-html/cell-53-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div></div>
<div id="69756011-acd6-404c-a5fc-7fe252cf20c8" class="cell markdown">
<ul>
<li>As we can see, and as it’s desired, the reward margins improve; this mirrors the loss curve and is a good sign</li>
<li>Note that DPO losses and reward margins are valuable metrics to track during training; however, they don’t tell the whole story</li>
<li>Lastly, and most importantly, we have to conduct a qualitative check of the responses</li>
<li>Here, we will look at the response (in addition, you could use an LLM to score the responses similar to chapter 7)</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [53]:</pre></div><div id="5EfUXJGOali8" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7ec7db47-d775-4646-f660-0d7f7e7c8503" data-execution_count="53">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> entry <span class="kw">in</span> val_data[:<span class="dv">3</span>]:</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>    input_text <span class="op">=</span> format_input(entry)</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>    token_ids <span class="op">=</span> generate(</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>reference_model,</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">=</span>text_to_token_ids(input_text, tokenizer).to(device),</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>        context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>        eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>    generated_text <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>    reference_response_text <span class="op">=</span> (</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>        generated_text[<span class="bu">len</span>(input_text):]</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>        .replace(<span class="st">"### Response:"</span>, <span class="st">""</span>)</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>        .strip()</span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>    token_ids <span class="op">=</span> generate(</span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>policy_model,</span>
<span id="cb84-24"><a href="#cb84-24" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">=</span>text_to_token_ids(input_text, tokenizer).to(device),</span>
<span id="cb84-25"><a href="#cb84-25" aria-hidden="true" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb84-26"><a href="#cb84-26" aria-hidden="true" tabindex="-1"></a>        context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb84-27"><a href="#cb84-27" aria-hidden="true" tabindex="-1"></a>        eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb84-28"><a href="#cb84-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-29"><a href="#cb84-29" aria-hidden="true" tabindex="-1"></a>    generated_text <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb84-30"><a href="#cb84-30" aria-hidden="true" tabindex="-1"></a>    policy_response_text <span class="op">=</span> (</span>
<span id="cb84-31"><a href="#cb84-31" aria-hidden="true" tabindex="-1"></a>        generated_text[<span class="bu">len</span>(input_text):]</span>
<span id="cb84-32"><a href="#cb84-32" aria-hidden="true" tabindex="-1"></a>        .replace(<span class="st">"### Response:"</span>, <span class="st">""</span>)</span>
<span id="cb84-33"><a href="#cb84-33" aria-hidden="true" tabindex="-1"></a>        .strip()</span>
<span id="cb84-34"><a href="#cb84-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-35"><a href="#cb84-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-36"><a href="#cb84-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(input_text)</span>
<span id="cb84-37"><a href="#cb84-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Correct response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>entry[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb84-38"><a href="#cb84-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Reference model response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>reference_response_text<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb84-39"><a href="#cb84-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Policy model response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>policy_response_text<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb84-40"><a href="#cb84-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">-------------------------------------</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Convert the active sentence to passive: 'The chef cooks the meal every day.'

Correct response:
&gt;&gt; The meal is cooked by the chef every day.

Reference model response:
&gt;&gt; The meal is cooked every day by the chef.

Policy model response:
&gt;&gt; The meal is prepared by the chef.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Classify an input string as either a noun or a verb.

### Input:
Dance

Correct response:
&gt;&gt; 'Dance' can be classified as a verb.

Reference model response:
&gt;&gt; "Dance" can be classified as a verb.

Policy model response:
&gt;&gt; The input string "Dance" could be classified as a verb.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Rewrite the sentence using a metaphor.

### Input:
The book is very interesting.

Correct response:
&gt;&gt; The book is a page-turner.

Reference model response:
&gt;&gt; The book is a treat.

Policy model response:
&gt;&gt; The book is a treat.

-------------------------------------
</code></pre>
</div>
</div></div>
<div id="RmcKVg0JlHVF" class="cell markdown">
<ul>
<li>As we can see based on the reference model and policy model responses above, the optimized model (i.e., the policy model) indeed slightly changed its style compared to the original model (i.e., reference model)</li>
<li>For instance, <code>"Dance" can be classified as a verb.</code> changed to <code>The input string "Dance" could be classified as a verb.</code> which is a slightly more polite response (the use of “could” instead of “can” makes the statement sound less assertive and more tentative)</li>
</ul>
</div>
<div class="cell-container"><div class="cell-decorator"><pre>In [54]:</pre></div><div id="jJSwb2hzQwdP" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6e755db4-9524-42a8-a58b-2218bf03e39a" data-execution_count="54">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> entry <span class="kw">in</span> test_data[:<span class="dv">3</span>]:</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    input_text <span class="op">=</span> format_input(entry)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    token_ids <span class="op">=</span> generate(</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>reference_model,</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">=</span>text_to_token_ids(input_text, tokenizer).to(device),</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>        eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>    generated_text <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>    reference_response_text <span class="op">=</span> (</span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>        generated_text[<span class="bu">len</span>(input_text):]</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>        .replace(<span class="st">"### Response:"</span>, <span class="st">""</span>)</span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a>        .strip()</span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a>    token_ids <span class="op">=</span> generate(</span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>policy_model,</span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a>        idx<span class="op">=</span>text_to_token_ids(input_text, tokenizer).to(device),</span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a>        context_size<span class="op">=</span>BASE_CONFIG[<span class="st">"context_length"</span>],</span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a>        eos_id<span class="op">=</span><span class="dv">50256</span></span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a>    generated_text <span class="op">=</span> token_ids_to_text(token_ids, tokenizer)</span>
<span id="cb86-30"><a href="#cb86-30" aria-hidden="true" tabindex="-1"></a>    policy_response_text <span class="op">=</span> (</span>
<span id="cb86-31"><a href="#cb86-31" aria-hidden="true" tabindex="-1"></a>        generated_text[<span class="bu">len</span>(input_text):]</span>
<span id="cb86-32"><a href="#cb86-32" aria-hidden="true" tabindex="-1"></a>        .replace(<span class="st">"### Response:"</span>, <span class="st">""</span>)</span>
<span id="cb86-33"><a href="#cb86-33" aria-hidden="true" tabindex="-1"></a>        .strip()</span>
<span id="cb86-34"><a href="#cb86-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-35"><a href="#cb86-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-36"><a href="#cb86-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(input_text)</span>
<span id="cb86-37"><a href="#cb86-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Correct response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>entry[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb86-38"><a href="#cb86-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Reference model response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>reference_response_text<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb86-39"><a href="#cb86-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Policy model response:</span><span class="ch">\n</span><span class="ss">&gt;&gt; </span><span class="sc">{</span>policy_response_text<span class="sc">.</span>strip()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb86-40"><a href="#cb86-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">-------------------------------------</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Rewrite the sentence using a simile.

### Input:
The car is very fast.

Correct response:
&gt;&gt; The car is as fast as lightning.

Reference model response:
&gt;&gt; The car is as fast as a cheetah.

Policy model response:
&gt;&gt; The car is as fast as a cheetah.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
What type of cloud is typically associated with thunderstorms?

Correct response:
&gt;&gt; The type of cloud typically associated with thunderstorms is cumulonimbus.

Reference model response:
&gt;&gt; A thunderstorm is a type of storm that typically produces thunder or lightning.

Policy model response:
&gt;&gt; The type of cloud typically associated with thunderstorms is a cumulus.

-------------------------------------

Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Name the author of 'Pride and Prejudice'.

Correct response:
&gt;&gt; Jane Austen.

Reference model response:
&gt;&gt; The author of 'Pride and Prejudice' is Jane Austen.

Policy model response:
&gt;&gt; The author of 'Pride and Prejudice' is Jane Austen.

-------------------------------------
</code></pre>
</div>
</div></div>


     </main> <!-- /main -->  <script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/your-website-url\.example\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>  </div> <!-- /content --> 
  
</body></html>